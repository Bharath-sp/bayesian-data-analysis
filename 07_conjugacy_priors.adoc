= Conjugacy Priors =
:doctype: book
:author: Bharath Kumar S P
:email: bharath030195@gmail.com
:stem: latexmath
:eqnums:
:toc:

== Introduction ==
When we model the prior distribution over Bernoulli parameter stem:[p], it is good to consider the beta distribution because the beta distribution has a functional form similar to that of likelihood (in terms of the parameter) and therefore it is easier to compute the posterior distribution in a closed form. Such (prior) distributions having similar functional form to that of likelihood are called conjugates of the likelihood.

== Conjugate Prior - Example ==
We can set stem:[\theta \sim \mathrm{Beta}(a, b)] as a prior to reflect how biased we think the coin is apriori to flipping it. This is a subjective judgment that represent stem:[a+b- 2] "imaginary" trials with stem:[a-1] heads and stem:[b-1] tails. What is our posterior belief about stem:[\theta] after observing stem:[n] heads and stem:[m] tails, stem:[f(\theta=\theta_r \,|\, X=n)]?

[stem]
++++
\begin{align*}
\\
    f(& \theta=\theta_r \,|\,X=n) \\
&=  \frac{P(X=n|\theta=\theta_r)f(\theta=\theta_r)}{P(X=n)} && \text{Bayes Theorem}\\
&= \frac{ { {n+m} \choose n} {\theta_r}^n(1-\theta_r)^m \cdot \frac{1}{c} \cdot {\theta_r}^{a-1}(1-\theta_r)^{b-1} } {P(X=n)} && \text{Binomial PMF, Beta PDF}\\
&= K \cdot {\theta_r}^n(1-\theta_r)^m \cdot  {\theta_r}^{a-1}(1-\theta_r)^{b-1} && \text{Combine Constants}\\
&= K \cdot {\theta_r}^{a+n-1}(1-\theta_r)^{b+m-1} && \text{Combine Like Bases}\\
\end{align*}
++++

NOTE: By constant, we mean those quantities that don't change as we change stem:[\theta].

Which is the PDF of stem:[\mathrm{Beta}(a+n, b+m)]. So stem:[\theta|X] also follows a beta distribution. It is pretty convenient that if we have a Beta prior belief, then our posterior belief is also Beta. This property where the type of distribution of the random variable is the same before and after an observation is called a *conjugate prior*.

Conjugate priors simplifies the process of updating beliefs as we get new data. Here we just have to add number of heads and tails seen to our initial beta parameters.

== Conjugacy in General ==
It is often not possible to compute the posterior distribution analytically. Conjugacy is computationally convenient because we can algebraically calculate our posterior distribution by updating the parameters of the prior distribution. For a given likelihood function stem:[p(\mathcal{D} \, | \, \theta)], a prior stem:[p(\theta)] is called a conjugate prior (to the likelihood) if the posterior stem:[p(\theta \, | \, \mathcal{D})] has the same algebraic form as the prior.

For example,

* When the likelihood is a binomial or Bernoulli, the conjugate prior is the beta distribution.
* When the likelihood is a multinomial, the conjugate prior is the Dirichlet distribution.
* When the likelihood is a Gaussian, the conjugate prior is the Gaussian distribution.

=== Beta-Binomial Conjugacy ===
Consider a Binomial random variable stem:[X \sim \mathrm{Bin}(N,p)] where stem:[N=n+m] with stem:[n] successess and stem:[m] failures,

[stem]
++++
P(X=n \,|\, N,p ) = { {n+m} \choose n} p^n(1-p)^m, n=0,1,\dots, N
++++

is the probability of finding stem:[n] times the outcome heads in stem:[n+m] coin flips, where stem:[p] is the probability of observing head in a single experiment. We place a beta prior on the parameter stem:[p], that is, stem:[p=\theta \sim \mathrm{Beta}(a, b)], where

[stem]
++++
\begin{align*}
    f(\theta=\theta_r \,|\, a,b) =
    \begin{cases}
    \frac{1}{B(a,b)}{\theta_r}^{a-1}(1-\theta_r)^{b-1} &\mbox{if } 0 \leq \theta_r \leq 1 \\
    0 & \mbox{otherwise}
    \end{cases}
   &&\mbox{where } B(a,b) =  \int_0^1 {\theta_r}^{a-1}(1-\theta_r)^{b-1} d\theta_r
\end{align*}
++++

If we now observe some data stem:[X=n], that is, we see stem:[n] heads in stem:[n+m] coin flips, we compute the posterior distribution on stem:[\theta] as:

[stem]
++++
\begin{align*}
f(\theta=\theta_r\,|\, a,b, n, n+m) & \propto P(X=n \,|\, n+m, \theta_r) f(\theta=\theta_r \,|\, a,b) \\
& \propto {\theta_r}^n(1-\theta_r)^m \cdot {\theta_r}^{a-1}(1-\theta_r)^{b-1} \\
& = {\theta_r}^{n+a-1} (1-\theta_r)^{m+b-1} \\
& \propto \mathrm{Beta}(a+n, b+m)
\end{align*}
++++

The posterior distribution is a Beta distribution as the prior. The Beta distribution is a conjugate prior for the parameter stem:[p] in the Binomial likelihood function. We can also say that Beta is a conjugate distribution for Binomial.

=== Beta-Bernoulli Conjugacy ===
Consider a Bernoulli random variable stem:[X \sim \mathrm{Ber}(p)] which has a PMF,

[stem]
++++
P(X=x \,|\, p) = \begin{cases}
p & \text{if } x =1\\
1-p & \text{if } x =0
\end{cases}
++++

This expression can also be written in continuous form as stem:[P(X=x \,|\, p) = p^{x} (1-p)^{1-x}]. We place a beta prior on the parameter stem:[p], that is, stem:[p=\theta \sim \mathrm{Beta}(a, b)].

[stem]
++++
\begin{align*}
    f(\theta=\theta_r \,|\, a,b) =
    \begin{cases}
    \frac{1}{B(a,b)}{\theta_r}^{a-1}(1-\theta_r)^{b-1} &\mbox{if } 0 \leq \theta_r \leq 1 \\
    0 & \mbox{otherwise}
    \end{cases}
   &&\mbox{where } B(a,b) =  \int_0^1 {\theta_r}^{a-1}(1-\theta_r)^{b-1} d\theta_r
\end{align*}
++++

If we now observe some data stem:[X=x], that is, we see either a success or a failure, then we compute the posterior distribution on stem:[\theta] as:

[stem]
++++
\begin{align*}
f(\theta=\theta_r\,|\, a,b,x) & \propto P(X=x \,|\, \theta_r) f(\theta=\theta_r \,|\, a,b) \\
& \propto {\theta_r}^x(1-\theta_r)^{1-x} \cdot {\theta_r}^{a-1}(1-\theta_r)^{b-1} \\
& = {\theta_r}^{x+a-1} (1-\theta_r)^{(1-x)+b-1} \\
& \propto \mathrm{Beta}(a+x, b+(1-x))
\end{align*}
++++

The posterior distribution is a Beta distribution as the prior. The Beta distribution is a conjugate prior for the parameter stem:[p] in the Bernoulli likelihood function.

=== Priors for Common Likelihoods ===
Conjugate priors for common likelihood functions:

image::.\images\conjugacy_01.png[align='left', 800, 700]

For a single Gaussian random variable:

image::.\images\conjugacy_02.png[align='left', 800, 600]

For multivariate Gaussian random variable:

image::.\images\conjugacy_03.png[align='left', 800, 600]

stem:[\lambda] is the parameter for Poisson, but if we were to turn stem:[\lambda] itself into a random variable, the right format of that random variable's distribution is Gamma.

For more: https://en.wikipedia.org/wiki/Conjugate_prior[Wikipedia].

The distributions used to represent our "prior" belief about a random variable will often have their own parameters. For example, a Beta distribution is defined using two parameters stem:[(a,b)]. Do we have to use parameter estimation to evaluate stem:[a] and stem:[b] too? No. Those parameters are called *hyperparameters*. That is a term we reserve for parameters in our model that we fix before running parameter estimation. 

== Special Priors ==
There are some priors that are used often.

=== Laplace Smoothing ===
A prior stem:[\theta \sim \mathrm{Beta}(a=2,b=2)] which represents one imagined heads and one imagined tails has a special name, Laplace Smoothing. People often use this as a prior instead of a uniform distribution. Some philosophical thought on why this is a popular choice,

"To talk about the probability of the sun rising, even though we have seen the sun rise every single day and we believe it will likely happen tomorrow, we want to imagine at least one failure and one success so we can hold in our mind some belief that it might not happen in the future".

We particularly use this prior so that we won't end up with a probability of 0 or 1 whenever we are estimating some probabilities.

=== Uniform is Beta ===
On deriving the expression for stem:[\mathrm{Beta}(a=1,b=1)]:

[stem]
++++
\begin{align*}
    f(\theta=\theta_r \,|\, 1,1) =
    \begin{cases}
    \frac{1}{B(a,b)}{\theta_r}^{a-1}(1-\theta_r)^{b-1} = \frac{1}{\int_0^1 1 d\theta_r} = \frac{1}{\theta_r |^1_0} = 1 &\mbox{if } 0 \leq \theta_r \leq 1 \\
    0 & \mbox{otherwise}
    \end{cases}
\end{align*}
++++

This is the PDF of continuous uniform distribution. So stem:[\mathrm{Beta}(a=1, b=1) = \mathrm{Uni}(0,1)]. Recall that stem:[\mathrm{Beta}(a=1, b=1)] means 0 imaginary heads and 0 imaginary tails. It is the same as saying we haven't seen any "imaginary" trials, so apriori we know nothing about the coin, so all probabilities are equally likely.